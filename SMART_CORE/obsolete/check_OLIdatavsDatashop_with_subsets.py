"""
Run Local Python Files
Command to be used for running -

#echo "Enter assessment_skill_mapping_file";
#read assessment_skill_mapping_file

python check_OLIdatavsDatashop_with_subsets.py $assessment_skill_mapping_file

For example -
python check_OLIdatavsDatashop_with_subsets.py Results/Assessment_skill_First-level_TF_10Assessment_v0.csv

"""

import sys
import csv
from collections import defaultdict
from safe_open import safe_open_wb

def correctstepname(assessment_skill_file):
	print("Running DataShop Extension")
	#Reading mappings from assessment-skill mapping generated by SMART-CORE
	stepnamesinOLI = [] #unused variable
	finname = "KC(SMART)"
	clustername = defaultdict()
	with open(assessment_skill_file, 'rU') as csvfile:
		csvreader = csv.reader(csvfile)
		for index, row in enumerate(csvreader):
			stepnamesinOLI.append(row[0])
			clustername[row[0]] = row[1]

	#Writing mappings to a new file inside the result folder prefixed with 'DataShop_' using above mappings and DataShop_Student_Step_rollup.csv
	stepnameinDS = []
	with open('/home/ieclab/OneDrive/PASTEL/SMART/Data/Inputs/DataShop_Student_Step_rollup.csv', 'r') as csvfile: #KC_model_reference.csv renamed to DataShop_Student_Step_rollup.csv
		csvreader = csv.reader(csvfile)
		outputFilename1 = assessment_skill_file[:-4] + '_DataShop_Student_Step_rollup.csv'
		with safe_open_wb(outputFilename1) as fin: #modified open(). It opens file in wb mode by creating parent directories if needed
		#with open(outputFilename1, 'wb') as fin:
			writer = csv.writer(fin)
			blank = ''
			for index, row in enumerate(csvreader):
				if index == 0:
					stepnameinDS.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], row[15], finname, row[16]])
					writer.writerows(stepnameinDS)                    
					continue
				
				if index == 3666:
					break
			
				if row[16] in clustername.keys():
					stepnameinDS = []	
					stepnameinDS.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], row[15], clustername[row[16]], row[16]])
					writer.writerows(stepnameinDS)

				else:
					stepnameinDS = []
					stepnameinDS.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], row[15], blank, row[16]])
					writer.writerows(stepnameinDS)
	
	#print("Created", outputFilename1)
	
	
	#Reading mappings from the above created file
	stepnamesinOLI = [] #unused variable
	clustername = defaultdict()
	with open(outputFilename1, 'rU') as csvfile:
		csvreader = csv.reader(csvfile)
		for index, row in enumerate(csvreader):
			stepnamesinOLI.append(row[17])
			clustername[row[17]] = row[16]

	#Writing mappings to a new file inside the result folder prefixed with 'DataShop_' using above mappings and ds_ref.csv
	stepnameinDS = []
	with open('/home/ieclab/OneDrive/PASTEL Project/SMART/Data/Inputs/DataShop_Transaction.csv', 'r') as csvfile: #ds_ref.csv renamed to DataShop_Transaction.csv
		csvreader = csv.reader(csvfile)
		outputFilename2 = assessment_skill_file[:-4] + '_DataShop_Transaction.csv'
		with safe_open_wb(outputFilename2) as fin: #modified open(). It opens file in wb mode by creating parent directories if needed
		#with open(outputFilename2, 'wb') as fin:
			writer = csv.writer(fin)
			blank = ''
			for index, row in enumerate(csvreader):
				if index == 0:
					stepnameinDS.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], row[15], row[16], row[17], row[18], row[19], row[20], row[21], row[22], row[23]])
					writer.writerows(stepnameinDS)                    
					continue

				if index == 418345:
					break
			
				if row[16] in clustername.keys():
					stepnameinDS = []	
					stepnameinDS.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], clustername[row[16]], row[16], row[17], row[18], row[19], row[20], row[21], row[22], row[23]])
					writer.writerows(stepnameinDS)
				else:
					stepnameinDS = []
					stepnameinDS.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9], row[10], row[11], row[12], row[13], row[14], blank, row[16], row[17], row[18], row[19], row[20], row[21], row[22], row[23]])
					writer.writerows(stepnameinDS)

	# The below .txt file is not required. csv format is good enough.
	# #Creating a tab-delimited (.txt) version of the above file inside the result folder prefixed 'DataShop_'	
	# print("Converting", outputFilename2, "to tab-delimited file...")
	# with open(outputFilename2) as inputFile:
	# 	#outputFilename3 = 'DataShop_'+assessment_skill_file+'.txt'
	# 	outputFilename3 = 'DataShop_' + assessment_skill_file + '_ds_ref.txt'
	# 	with open(outputFilename3, 'w') as outputFile:
	# 		reader = csv.DictReader(inputFile, delimiter=',')
	# 		writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\t')
	# 		writer.writeheader()
	# 		writer.writerows(reader)

	# print (outputFilename3)

	print (outputFilename2)
	
	
if __name__ == '__main__':
	assessment_skill_mapping_file = sys.argv[1] #filename along with path
	correctstepname(assessment_skill_mapping_file)
